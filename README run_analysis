==================================================================
RUN_ANALYSIS.R SCRIPT
==================================================================
Drew Langenberg

Source data:
Human Activity Recognition Using Smartphones Dataset
Version 1.0
Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto.
Smartlab - Non Linear Complex Systems Laboratory
DITEN - Università degli Studi di Genova.
www.smartlab.ws
==================================================================


==================================================================
NOTES FOR THE GRADER
==================================================================

The script assumes that the "UCI HAR Dataset" file is in the working directory for the current R session, and that the dataset fileS (test, train, etc.) are all inside the "UCI HAR Dataset" file as they were originally downloaded.

TO READ THE OUTPUT FILE BACK INTO R, PLACE THE FILE IN YOUR WORKING DIRECTORY AND RUN THIS SCRIPT:
read.table("run_analysis.txt", header = TRUE)



==================================================================
BACKGROUND
**adapted from the original README supplied with the "UCI HAR Dataset"
==================================================================

This dataset was compiled from the "Human Activity Recognition Using Smartphones Dataset" created by J. Reyes-Ortiz, D. Anguita, A. Ghio and L. Oneto. 

The original experiments were performed with a group of 30 volunteers between 19 and 48 years old. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. 3-axial linear acceleration and 3-axial angular velocity were captured Using the phone's embedded accelerometer and gyroscope.

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details. 


==================================================================
DATA PROVIDED
==================================================================
- mean and standard deviation for 79 measurements grouped by the activity being performed and the unique ID for the subject involved.


==================================================================
DATASET INCLUDES THE FOLLOWING FILES
==================================================================
- 'README.txt'

- 'codebook.md': a code book that lists all levels of all variables, provides definitions for all labels and describes how the original dataset was shaped to form the new dataset.

- 'run_analysis.R': an R script written to take raw input from the UCI HAR dataset and output a tidy, processed dataset.

- 'run_analysis.txt': the final, tidy dataset produced by the 'run_analysis.R' script


==================================================================
BACKGROUND ON ORIGINAL SOURCE DATA
==================================================================
For more information about the original dataset, visit: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones

Access the original data used to create this dataset at: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip


